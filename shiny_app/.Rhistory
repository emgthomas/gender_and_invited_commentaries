### Functions ###
pi_z_fun <- function(x,pi_z,beta_z) sum(pi_z/(1+exp(-x*beta_z)))
KL_beta <- function(beta,x){
p_x <- sapply(x,pi_z_fun,pi_z=pi_z,beta_z=beta_z)
g <- mean(log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x))
return(g)
}
beta_plot <- seq(min(beta_z),max(beta_z),0.01)
g_plot <- sapply(X=beta_plot,FUN=KL_beta,x=X)
plot(beta_plot,g_plot,type="l",xlab="beta",ylab="g(beta)")
min(g_plot)
max(g_plot)
summary(g_plot)
beta_plot <- seq(min(beta_z),max(beta_z),0.01)
summary(beta_plot)
x <- X
p_x <- sapply(x,pi_z_fun,pi_z=pi_z,beta_z=beta_z)
summary(p_x)
min(p_X)
g <- mean(log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x))
summary(g)
blah <- log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x)
summary(blah)
max(X'')
max(X)
x <- max(X)
blah <- log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x)
blha
blah
x
blah <- log(1+exp(-x*beta))*pi_z_fun(x=x,pi_z=pi_z,beta_z=beta_z) + log(1+exp(x*beta))*(1-pi_z_fun(x=x,pi_z=pi_z,beta_z=beta_z))
blah
log(1+exp(x*beta))
log(1+exp(-x*beta))
log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x)
x
p_x
beta <- 1
beta <- beta_KL
log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x)
cd("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/")
setwd("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simulate_data_comparison1.Rdata")
ls()
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/data_example_results/comparison_vi_results1.Rdata")
ls)
ls()
groups <- as.integer(as.factor(out_vi$moretrees_est))
groups
outcomes <- which(groups==6)
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e/\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv")
rm(list=ls())
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv")
betasims <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv")
names(betasims)
?read.csv
betasims <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=10)
dim(betasims)
names(betasims)
betasims <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=433)
dim(betasims)
betasims <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=432)
dim(betasims)
length(betasims[,2])
length(unique(betasims[,2]))
ls()
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
ls()
rm(list=ls())
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
ls()
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/inputs.Rdata")
ls()
dim(beta)
length(beta)
true_beta <- beta[[1]]
beta_true <- beta[[1]]
beta_est <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=432)[,2]
length(beta_est)
length(unique(beta_est))
length(unique(beta_true))
beta_true
beta_true <- beta <- V(tree)$beta1[(p-pL+1):p]
require(igraph)
beta_true <- beta <- V(tree)$beta1[(p-pL+1):p]
length(unique(beta_true))
groups <- as.integer(as.factor(beta_est))
ls()
groups_true <- as.integer(as.fator(beta_true))
groups_true <- as.integer(as.factor(beta_true))
outcomes
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/inputs.Rdata")
beta_est <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=432)[,2]
groups_est <- as.integer(as.factor(beta_est))
outcomes <- which(groups_est==6)
x <- unlist(Z.sim[outcomes])
groups_true <- as.integer(as.factor(beta_true))
groups_true_within <- groups_true[outcomes]
groups_true_within
groups_est <- as.integer(as.factor(beta_est))
max(groups_est)
table(groups_est)
groups_count <- table(groups_est)
biggest_group <- names(groups_count)[which.max(groups_count)]
biggest_group
biggest_group <- as.integer(names(groups_count)[which.max(groups_count)])
biggest_group
outcomes <- which(groups_est==biggest_group)
x <- unlist(Z.sim[outcomes])
groups_true <- as.integer(as.factor(beta_true))
groups_true_within <- groups_true[outcomes]
beta_true_within <- beta_true[outcomes]
beta_true_within
pi_z <- table(beta_true_within)/length(beta_true_within)
pi_z
beta_z <- as.numeric(names(pi_z))
beta_z
pi_z
names(pi_z) <- NULL
pi_z
names(pi_z) <- NA
pi_z
names(pi_z) <- NULL
pi_z
class(pi_z)
pi_z <- as.numeric(pi_z)
pi_z
require(igraph)
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/inputs.Rdata")
beta_true <- beta <- V(tree)$beta1[(p-pL+1):p]
beta_est <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=432)[,2]
groups_est <- as.integer(as.factor(beta_est))
groups_count <- table(groups_est)
biggest_group <- as.integer(names(groups_count)[which.max(groups_count)])
outcomes <- which(groups_est==biggest_group)
X <- unlist(Z.sim[outcomes])
groups_true <- as.integer(as.factor(beta_true))
groups_true_within <- groups_true[outcomes]
beta_true_within <- beta_true[outcomes]
pi_z <- table(beta_true_within)/length(beta_true_within)
beta_z <- as.numeric(names(pi_z))
pi_z <- as.numeric(pi_z)
### Functions ###
pi_z_fun <- function(x,pi_z,beta_z) sum(pi_z/(1+exp(-x*beta_z)))
g_fun <- function(beta,x){
p_x <- sapply(x,pi_z_fun,pi_z=pi_z,beta_z=beta_z)
g <- mean(log(1+exp(-x*beta))*p_x + log(1+exp(x*beta))*(1-p_x))
return(g)
}
beta_plot <- seq(min(beta_z),max(beta_z),0.01)
g_plot <- sapply(X=beta_plot,FUN=g_fun,x=X)
plot(beta_plot,g_plot,type="l",xlab="beta",ylab="g(beta)")
beta_plot <- seq(min(beta_z),max(beta_z),length.out=100)
beta_plot <- seq(min(beta_z),max(beta_z),length.out=100)
g_plot <- sapply(X=beta_plot,FUN=g_fun,x=X)
g_plot <- sapply(X=beta_plot,FUN=g_fun,x=X)
plot(beta_plot,g_plot,type="l",xlab="beta",ylab="g(beta)")
(beta_KL <- optimize(g_fun,interval=c(min(beta_z),max(beta_z)),x=X,maximum=F)$minimum)
sum(beta_z*pi_z)/sum(pi_z)
x <- seq(min(X),max(X),length.out=1000)
correct_mod <- function(x,y,beta_z,pi_z){
sum(pi_z/(1+exp(-y*x*beta_z)))
}
misspec_mod <- function(x,y,beta){
1/(1+exp(-y*x*beta))
}
logit_correct <- sapply(x,FUN=correct_mod,y=1,beta_z=beta_z,pi_z=pi_z)
logit_misspec_KL <- sapply(x,FUN=misspec_mod,y=1,beta=beta_KL)
plot(x,logit_correct,type="l",xlab="X",ylab="P(Y=1|X)",lty=1)
plot(x,logit_correct,type="l",xlab="X",ylab="P(Y=1|X)",lty=1)
lines(x,logit_misspec_KL,col="red",lty=2)
plot(x,logit_correct,type="l",xlab="X",ylab="P(Y=1|X)",lty=1)
lines(x,logit_misspec_KL,col="red",lty=2)
summary(X)
length(unique(beta_est))
length(unique(beta_true))
length(beta_true_within)
length(unique(beta_true_within))
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/simdat_n1e\\+05.Rdata")
load("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_inputs/inputs.Rdata")
beta_est <- read.csv("/Users/emt380/Documents/PhD_Papers/Air_pollution/R_code/MORETreeS/moretrees/simulation_results/betasims_n1e+05_beta1.csv",nrow=432)[,2]
groups_est <- as.integer(as.factor(beta_est))
groups_count <- table(groups_est)
biggest_group <- as.integer(names(groups_count)[which.max(groups_count)])
outcomes <- which(groups_est==biggest_group)
X <- unlist(Z.sim[outcomes])
groups_true <- as.integer(as.factor(beta_true))
groups_true_within <- groups_true[outcomes]
beta_true_within <- beta_true[outcomes]
pi_z <- table(beta_true_within)/length(beta_true_within)
beta_z <- as.numeric(names(pi_z))
pi_z <- as.numeric(pi_z)
length(X)
# beta_plot <- seq(min(beta_z),max(beta_z),length.out=100)
beta_plot <- seq(-100,100,length.out=100)
g_plot <- sapply(X=beta_plot,FUN=g_fun,x=X)
g_plot <- sapply(X=beta_plot,FUN=g_fun,x=X)
plot(beta_plot,g_plot,type="l",xlab="beta",ylab="g(beta)")
min(g_plot)
max(g_plot)
# beta_plot <- seq(min(beta_z),max(beta_z),length.out=100)
beta_plot <- seq(-10,10,length.out=100)
g_plot <- sapply(X=beta_plot,FUN=g_fun,x=X)
plot(beta_plot,g_plot,type="l",xlab="beta",ylab="g(beta)")
sum(beta_z*pi_z)
x <- seq(min(X),max(X),length.out=1000)
correct_mod <- function(x,y,beta_z,pi_z){
sum(pi_z/(1+exp(-y*x*beta_z)))
}
misspec_mod <- function(x,y,beta){
1/(1+exp(-y*x*beta))
}
logit_correct <- sapply(x,FUN=correct_mod,y=1,beta_z=beta_z,pi_z=pi_z)
logit_misspec_KL <- sapply(x,FUN=misspec_mod,y=1,beta=beta_KL)
logit_misspec_mean <- sapply(x,FUN=misspec_mod,y=1,beta=beta_mean)
shiny::runApp('Documents/PhD_Papers/Gender_bias/R_code/gender_bias_invited_commentary/github/shiny_app')
# ---------------------------------------------------------- #
# --------------------- Data cleaning ---------------------- #
# ---------------------------------------------------------- #
#######################################################################
sink(file="./results/data_cleaning.txt")
#######################################################################
# packages
require(data.table)
require(dplyr)
require(gtools)
require(reshape2)
# Read in publications data
publications <- readRDS(file="./data/publications_raw.rds")
cat("------- Flow chart Step 1 (Included)-------\n\n")
cat("Number of included journals was determined in Scopus database (not shown here)")
cat("\n\n------- Flow chart Step 1 (Excluded)-------\n\n")
cat("Number of journals that did not contain ICC articles = ",4412 + 56 - length(unique(publications$pub_sourceid)))
cat("\n\n------- Flow chart Step 2 (Included)------- \n\n")
cat("Number of ICC articles = ",nrow(publications))
# Read in author data
authors <- readRDS(file="./data/authors_raw.rds")
cat("\n\n------- Flow chart Step 2 (Excluded)------- \n\n")
cat("Number of ICC articles where corresponding/single author could not be identified = ",nrow(publications)-length(unique(authors$pub_id[authors$case==1])))
cat("\n\n------- Flow chart Step 3 (Included)------- \n\n")
cat("Number of ICC articles with corresponding/single author = ",length(unique(authors$pub_id[authors$case==1])))
# Merge journal source IDs into authors dataset
authors2 <- merge(x=authors,y=publications,by.x="pub_id",all.x=T,all.y=F,sort=F)
cat("\n\n------- Flow chart Step 4 (Included)------- \n\n")
cat("Number of unique corresponding author-journal pairs (these will form cases) = ",sum(!duplicated(authors2[authors2$case==1,c("auth_id","pub_sourceid")])))
cat("\n\n------- Flow chart Step 5 (Included)------- \n\n")
cat("Number of controls = ",sum(1-authors2$case))
# Discard controls in bottom quartile of Match Score
ms_1st_quartile <- quantile(authors2$Match_Score[authors2$case==0],0.25)
authors3 <- authors2[authors2$Match_Score > ms_1st_quartile,]
# Remove controls that are also cases (within the same journal)
# and remove duplicate case authors within the same journal
# So, within journals, cases cannot also be controls, and each author can be a case only once
controls <- authors3[authors3$case==0,] # separate out controls
cases <- authors3[authors3$case==1,] # separate out cases
controls.keep <- logical(length=nrow(controls))
cases.keep <- logical(length=nrow(cases))
# Also, determine which cases *only* wrote replies/response to letters/commentaries within each journal
# (these will be excluded in a sensitivity analysis)
cases.only_replies <- logical(length=nrow(cases))
i <- 0
cat("\n\nProcessing data for ",length(unique(controls$pub_sourceid)),"journals...\n\n")
for(pub in unique(controls$pub_sourceid)){
i <- i+1
which_controls <- controls$pub_sourceid == pub
which_cases <- cases$pub_sourceid == pub
# within journals, remove any controls that are also cases
controls.keep[which_controls] <- !(controls$auth_id[which_controls] %in% unique(cases$auth_id[which_cases]))
# within journals, remove any duplicate cases
cases.keep[which_cases] <- !duplicated(cases$auth_id[which_cases])
# check which authors *only* wrote replies/response in this journal
only_replies <- tapply(cases$replies[which_cases],cases$auth_id[which_cases],mean) # compute fraction of cases per author which are replies
only_replies <- as.numeric(names(only_replies)[only_replies==1]) # if fraction is one, that author only wrote replies in this journal
cases.only_replies[which_cases & cases$auth_id %in% only_replies] <- T
if((i %% 100)==0) print(i)
}
cat("\n\nDone.\n\n")
# put cases and controls back together
cases$only_replies <- cases.only_replies
controls$only_replies <- NA
authors4 <- rbind(cases[cases.keep,],controls[controls.keep,])
authors4$replies <- NULL
publications$replies <- NULL
cat("\n\n------- Flow chart Step 5 (Excluded)------- \n\n")
cat("Number of controls excluded = ",sum(1-authors2$case) - sum(1-authors4$case))
# Keep only top 10 controls
authors5 <- authors4 %>%
group_by(pub_id) %>%
mutate(match_score_rank = frank(-Match_Score))
authors5 <- authors5[order(authors5$pub_id,authors5$Match_Score,decreasing=T),]
# View(authors5[,c("pub_id","case","Match_Score","match_score_rank")])
authors5 <- authors5[authors5$match_score_rank <= 11, ] # keep 11 because the top match is always the case themself
cat("\n\n------- Flow chart Step 6 (Included)------- \n\n")
cat("Number of controls included after keeping only top 10 = ",sum(1-authors5$case))
#cat("Number of unique control authors included after keeping only top 10 = ",length(unique(authors5$auth_id[authors5$case==0])))
# Include only matched sets that have a case and at least one control
# i.e., remove invalid matched sets
checkFun <- function(status){
if(length(status)==1) return(FALSE)
if(sum(status) == 1 & length(status) > 1){
return(TRUE)
} else {
return(FALSE)
}
}
authors5$pub_id <- factor(authors5$pub_id,levels=unique(authors5$pub_id))
included.pubs <- tapply(authors5$case,authors5$pub_id,FUN=checkFun,simplify = T)
included.pubs <- data.frame(pub_id=names(included.pubs),include=included.pubs)
authors6 <- merge(authors5,included.pubs,by="pub_id",all.x=T)
authors6 <- authors6[authors6$include,]
authors6$include <- NULL
cat("\n\n------- Flow chart Step 7 (Included)------- \n\n")
cat("Number of matched sets = ",sum(authors6$case))
# For remaining controls, categorize match score into deciles
authors6$match_quantile <- numeric(length=nrow(authors6)) + NA
# find quantiles of match score for controls
authors6$match_quantile[authors6$case==0] <- quantcut(authors6$Match_Score[authors6$case==0],q=10)
# set "quantile" to 11 for cases, so they will always be included
authors6$match_quantile[authors6$case==1] <- 11
### put this together in final dataset
# "icc" stands for "intra-citing commentary"
icc_df_all <- authors6
# Remove authors with no gender designation
icc_df <- icc_df_all[icc_df_all$Gender != "unknown",]
icc_df$Publication <- factor(icc_df$pub_id,levels=unique(icc_df$pub_id))
included.pubs <- tapply(icc_df$case,icc_df$pub_id,FUN=checkFun,simplify = T)
included.pubs <- data.frame(pub_id=names(included.pubs),include=included.pubs)
icc_df <- merge(icc_df,included.pubs,by="pub_id",all.x=T)
icc_df <- icc_df[icc_df$include,]
icc_df$include <- NULL
cat("\n\n------- Flow chart Step 7 (Excluded)------- \n\n")
cat("Matched sets excluded due to missing gender = ",sum(authors6$case) - sum(icc_df$case))
cat("\n\n------- Flow chart Step 8 (Included)------- \n\n")
cat("Matched sets with complete gender information = ",sum(icc_df$case))
cat("\n\n------- Flow chart Step 9 (Included)------- \n\n")
cat("Number of journals in one-stage meta-analysis = ",length(unique(icc_df$pub_sourceid)))
###### Identify journals for which we can get a valid journal-level OR estimate ########
min_num_matched_sets <- 2
check_genders <- function(gender) length(unique(gender))==2
check_matched_sets <- function(idx,publications,gender,case,min_num_matched_sets){
publications <- publications[idx]
gender <- gender[idx]
case <- case[idx]
# which matched sets are not all the same gender?
out1 <- tapply(gender,as.character(publications),check_genders)
# after excluding matched sets that are all the same gender, there any "zero cells"?
out2 <- sum(table(gender[publications %in% names(out1)[out1]],case[publications %in% names(out1)[out1]])==0)
return(sum(out1)>=min_num_matched_sets & out2==0)
}
icc_df$Publication <- factor(icc_df$pub_id,levels=unique(icc_df$pub_id))
icc_df$pub_sourceid <- factor(icc_df$pub_sourceid,levels=unique(icc_df$pub_sourceid))
icc_df$Gender <- factor(icc_df$Gender,unique(icc_df$Gender))
included.journals <- tapply(1:nrow(icc_df),
icc_df$pub_sourceid,
check_matched_sets,
publications=icc_df$pub_id,
gender=icc_df$Gender,
case=icc_df$case,min_num_matched_sets=min_num_matched_sets)
included.journals <- data.frame(pub_sourceid=names(included.journals),include.journal=included.journals)
icc_df <- merge(icc_df,included.journals,by="pub_sourceid")
cat("\n\n------- Flow chart Step 9 (Excluded)------- \n\n")
cat("Journals with insufficient data for journal-specific estimate = ",length(included.journals$include.journal) - sum(included.journals$include.journal))
cat("\n\n------- Flow chart Step 10 (Included)------- \n\n")
cat("Journals with enough data for journal-specific estimate = ",sum(included.journals$include.journal))
cat("\n\nNumber of matched sets in these journals = ",sum(icc_df$case[icc_df$include.journal]))
# Create factor variables
icc_df$Gender <- factor(icc_df$Gender, levels=c("male","female"))
icc_df$pub_id <- factor(icc_df$pub_id, levels=unique(icc_df$pub_id))
icc_df$auth_id <- factor(icc_df$auth_id,levels=unique(icc_df$auth_id))
icc_df_all$Gender <- factor(icc_df_all$Gender, levels=c("male","female","unknown"))
icc_df_all$pub_id <- factor(icc_df_all$pub_id, levels=unique(icc_df_all$pub_id))
icc_df_all$auth_id <- factor(icc_df_all$auth_id,levels=unique(icc_df_all$auth_id))
# Measures of author seniority
icc_df$years_in_scopus <- 2019 - icc_df$First_Year_in_Scopus
icc_df_all$years_in_scopus <- 2019 - icc_df_all$First_Year_in_Scopus
icc_df$years_in_scopus_quintile <- as.numeric(quantcut(icc_df$years_in_scopus,q=5))
icc_df$h_index_quintile <- as.numeric(quantcut(icc_df$H_Index,q=5))
icc_df$n_pubs_quintile <- as.numeric(quantcut(icc_df$Total_Publications_In_Scopus,q=5))
#### Compute percentiles for seniority measures ####
# icc_df
YiS <- icc_df[,c("years_in_scopus","auth_id")]
YiS <- YiS[!duplicated(YiS),]
YiS$years_in_scopus_ptile <- percent_rank(YiS$years_in_scopus)/0.1
icc_df <- merge(icc_df,YiS[,c("auth_id","years_in_scopus_ptile")],by="auth_id",all.x=T,all.y=F)
h_index <- icc_df[,c("H_Index","auth_id")]
h_index <- h_index[!duplicated(h_index),]
h_index$h_index_ptile <- percent_rank(h_index$H_Index)/0.1
icc_df <- merge(icc_df,h_index[,c("auth_id","h_index_ptile")],by="auth_id",all.x=T,all.y=F)
n_pubs <- icc_df[,c("Total_Publications_In_Scopus","auth_id")]
n_pubs <- n_pubs[!duplicated(n_pubs),]
n_pubs$n_pubs_ptile <- percent_rank(n_pubs$Total_Publications_In_Scopus)/0.1
icc_df <- merge(icc_df,n_pubs[,c("auth_id","n_pubs_ptile")],by="auth_id",all.x=T,all.y=F)
# icc_df_all
YiS <- icc_df_all[,c("years_in_scopus","auth_id")]
YiS <- YiS[!duplicated(YiS),]
YiS$years_in_scopus_ptile <- percent_rank(YiS$years_in_scopus)/0.1
icc_df_all <- merge(icc_df_all,YiS[,c("auth_id","years_in_scopus_ptile")],by="auth_id",all.x=T,all.y=F)
h_index <- icc_df_all[,c("H_Index","auth_id")]
h_index <- h_index[!duplicated(h_index),]
h_index$h_index_ptile <- percent_rank(h_index$H_Index)/0.1
icc_df_all <- merge(icc_df_all,h_index[,c("auth_id","h_index_ptile")],by="auth_id",all.x=T,all.y=F)
n_pubs <- icc_df_all[,c("Total_Publications_In_Scopus","auth_id")]
n_pubs <- n_pubs[!duplicated(n_pubs),]
n_pubs$n_pubs_ptile <- percent_rank(n_pubs$Total_Publications_In_Scopus)/0.1
icc_df_all <- merge(icc_df_all,n_pubs[,c("auth_id","n_pubs_ptile")],by="auth_id",all.x=T,all.y=F)
#### Merge in Asian origin data ####
authors_asian <- readRDS("./data/authors_asian.rds")
# merge into authors dataset
icc_df_all <- merge(icc_df_all,authors_asian,by="auth_id",all.x=T,all.y=F)
#### Merge in journal topics ####
# Read in journal topics
journal_topics <- read.csv(file="./data/All_Journals_ASJC.csv")
# Keep only medical or multidisciplinary topics (some journals have extra ASJC codes outside our range of interest)
journal_topics <- journal_topics[(journal_topics$AJSC_Codes < 2800 & journal_topics$AJSC_Codes >= 2700) |
journal_topics$AJSC_Codes==1000,]
journal_names <- journal_topics[!duplicated(journal_topics$pub_sourceid),c("pub_sourceid","sourcetitle")]
topic_names <- read.csv(file="./data/ASJC Codes with levels.csv",
sep=";") # cloned from github.com/plreyes/Scopus.git
journal_topics <- merge(x=journal_topics,y=topic_names,
by.x="AJSC_Codes",by.y="Code",
all.x=T)
# Create dataframe of topics by journal
journal_topics_low <- dcast(journal_topics,pub_sourceid ~ Low,fun.aggregate = length, value.var="Low")
journal_topics_low <- merge(journal_topics_low,journal_names,by="pub_sourceid")
journal_topics_low <- journal_topics_low[,c(ncol(journal_topics_low),1:(ncol(journal_topics_low)-1))]
############## Save data #############
saveRDS(icc_df_all,file="./data/processed_data_all.rds")
saveRDS(icc_df,file="./data/processed_data_no_missing.rds")
saveRDS(journal_topics_low,file="./data/journal_topics.rds")
#######################################################################
sink()
#######################################################################
getwd()
setwd("./Documents/PhD_Papers/Gender_bias/R_code/gender_and_invited_commentaries/github/")
## packages
require(survival)
require(metafor)
require(splines)
require(forestplot)
require(plotly)
require(RColorBrewer)
require(lmtest)
## some colors
cols1 <- brewer.pal(9,name="BuGn")
cols2 <- brewer.pal(9,name="Oranges")
## global functions
source("./code/functions.R")
## load data
outputs_select <- readRDS(file="./shiny_app/journal_ORs.rds")
icc_df <- readRDS(file="./data/processed_data_no_missing.rds")
topics_list <- readRDS(file="./shiny_app/topics_list.rds")
journal_topics <- readRDS(file = "./data/journal_topics.rds")
journal_topics <- journal_topics[journal_topics$pub_sourceid %in% unique(icc_df$pub_sourceid),]
cat("\n\n------------ Effect modification by journal citescore ----------------\n\n")
cat("********** Undjusted model ************\n\n")
# exclude one journal with high outlier citescore
icc_df_cs <- subset(icc_df,citescore<20)
outputs_select2 <- subset(outputs_select,citescore<20)
cat("Journal with outlier citescore of",max(icc_df$citescore),":",
as.character(unique(icc_df$pub_source_title[icc_df$citescore>20])))
# define knots
n_knots <- 3 # number of *internal* knots
citescore_by_pub <- icc_df_cs$citescore[icc_df_cs$case==1]
knot_placement <- quantile(citescore_by_pub,probs = seq(0,1,length.out=n_knots+2)[2:(n_knots+1)])
icc_df_cs$gender <- as.numeric(icc_df_cs$Gender == "female")
citescore_ns <- ns(icc_df_cs$citescore,knots=knot_placement)
icc_df_cs$citescore_gender_1 <- citescore_ns[,1]*icc_df_cs$gender
icc_df_cs$citescore_gender_2 <- citescore_ns[,2]*icc_df_cs$gender
icc_df_cs$citescore_gender_3 <- citescore_ns[,3]*icc_df_cs$gender
icc_df_cs$citescore_gender_4 <- citescore_ns[,4]*icc_df_cs$gender
icc_df_cs$citescore_gender <- icc_df_cs$citescore*icc_df_cs$gender
# run regression with interaction by journal cite score
knots <- c(2.5,5,7.5)
all_1stage_cs <- clogit(case ~ gender +
citescore_gender_1 + citescore_gender_2 +
citescore_gender_3 + citescore_gender_4 +
strata(pub_id), data = icc_df_cs)
summary(all_1stage_cs)
# model without effect modifcation by cite score
all_1stage <- clogit(case ~ gender + strata(pub_id), data = icc_df_cs)
cat("\n\nTest for null hypothesis of no effect of Cite Score on odds ratio\n\n")
lrtest(all_1stage_cs,all_1stage)
# run regression
knots <- c(2.5,5,7.5)
all_1stage_cs_adj <- clogit(case ~ gender +
citescore_gender_1 + citescore_gender_2 + citescore_gender_3 + citescore_gender_4 +
ns(years_in_scopus_ptile,knots=knots) +
ns(h_index_ptile,knots=knots) +
ns(n_pubs_ptile,knots=knots) +
strata(pub_id), data = icc_df_cs)
summary(all_1stage_cs_adj)
# model without effect modifcation by cite score
all_1stage_adj <- clogit(case ~ gender +
ns(years_in_scopus_ptile,knots=knots) +
ns(h_index_ptile,knots=knots) +
ns(n_pubs_ptile,knots=knots) +
strata(pub_id), data = icc_df_cs)
cat("\n\nTest for null hypothesis of no effect of Cite Score on odds ratio\n\n")
lrtest(all_1stage_cs_adj,all_1stage_adj)
rm(list=ls())
setwd("./shiny_app/")
shiny::runApp()
runApp()
runApp()
runApp()
